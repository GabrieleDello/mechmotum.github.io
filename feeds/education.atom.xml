<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Bicycle Laboratorium - education</title><link href="https://mechmotum.github.io/" rel="alternate"></link><link href="https://mechmotum.github.io/feeds/education.atom.xml" rel="self"></link><id>https://mechmotum.github.io/</id><updated>2020-06-22T00:00:00-07:00</updated><subtitle>E pur si muove</subtitle><entry><title>Developing a LibreTexts Editor Plugin For Inserting Executable Code Blocks</title><link href="https://mechmotum.github.io/blog/libretexts-jupyter-plugin.html" rel="alternate"></link><published>2020-06-22T00:00:00-07:00</published><updated>2020-06-22T00:00:00-07:00</updated><author><name>Hao Huang</name></author><id>tag:mechmotum.github.io,2020-06-22:/blog/libretexts-jupyter-plugin.html</id><summary type="html">&lt;p class="first last"&gt;Blog post on creating a CKEditor plugin which could insert
executable code blocks&lt;/p&gt;
</summary><content type="html">&lt;div class="section" id="background"&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;During the end of the Fall Quarter 2019 and Winter Quarter 2020, we focused on
building a &lt;a class="reference external" href="https://github.com/LibreTexts/ckeditor-binder-plugin"&gt;CKEditor Binder Plugin&lt;/a&gt; to be used on the
&lt;a class="reference external" href="https://libretexts.org"&gt;LibreTexts&lt;/a&gt; website to allow textbook authors to
insert executable code blocks. We intend for both textbook authors and readers
to have the ability to edit and run code blocks efficiently, making online
educational content more interactive.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="build-process"&gt;
&lt;h2&gt;Build Process&lt;/h2&gt;
&lt;p&gt;We started the project by &lt;a class="reference external" href="https://docs.google.com/document/d/1eV08l_4djKJ7bc8r0LPbD5bp3QT7mHTZgABUleH15H0/edit?usp=sharing"&gt;surveying&lt;/a&gt;
LibreTexts authors and readers on their most requested features.&lt;/p&gt;
&lt;div class="section" id="binderhub"&gt;
&lt;h3&gt;BinderHub&lt;/h3&gt;
&lt;p&gt;On the backend, the CKEditor Binder plugin utilizes a project called &lt;a class="reference external" href="https://binderhub.readthedocs.io/en/latest/"&gt;BinderHub&lt;/a&gt; to run code blocks. BinderHub
is developed as part of the Jupyter project and gives custom computing
environments based on a list of requirements specified through a GitHub
repository.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="thebelab"&gt;
&lt;h3&gt;Thebelab&lt;/h3&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/minrk/thebelab"&gt;Thebelab&lt;/a&gt; and  &lt;a class="reference external" href="https://github.com/ines/juniper"&gt;Juniper&lt;/a&gt; are two examples of projects which can
insert code blocks into HTML pages and running them by requesting a kernel from
a computing backend like BinderHub. We found that Juniper had some better deign
elements; however, Thebelab was more actively maintained.  We deliberated on
which project to incorporate into our plugin, and decided to use Thebelab since
the recent commits indicated that any possible need for help would be more
promptly met. To incorporate some of the streamlined design elements of
Juniper, we planned on adding syntax highlighting.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="creating-the-plugin"&gt;
&lt;h3&gt;Creating the plugin&lt;/h3&gt;
&lt;p&gt;Our plugin is based on the &lt;a class="reference external" href="https://ckeditor.com/docs/ckeditor4/latest/"&gt;CKEditor 4&lt;/a&gt;, an open source “what you see
is what you get” text editor. This is the editor authors use on the LibreTexts
website.&lt;/p&gt;
&lt;p&gt;Our approach to this plugin is to make use of a &lt;a class="reference external" href="https://ckeditor.com/docs/ckeditor4/latest/guide/widget_sdk_intro.html"&gt;widget&lt;/a&gt;, on
the editor which allows us to place all the HTML elements of Thebelab together
as one unit. In other words the widget is a component made out of multiple
separate elements that are grouped together for easy formatting and movement;
however, individual parts can be altered independently. This allows for the
CKEditor instance to easily enforce the elements. Additionally, we created a
&lt;a class="reference external" href="https://ckeditor.com/docs/ckeditor4/latest/guide/dev_howtos_dialog_windows.html"&gt;dialog window&lt;/a&gt;
for each code block so that users can modify each block whenever they want.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="mindtouch-specific-settings"&gt;
&lt;h3&gt;Mindtouch Specific Settings&lt;/h3&gt;
&lt;p&gt;One of the challenges we faced was working around Mindtouch, which sometimes
caused the plugin to function in unexpected ways. For reference, Mindtouch is
the web based wiki software that Libretexts uses and it uses a CKEditor. An
example of an obstacle we faced was that Mindtouch seemed to apply its own CSS
to the plugin.  This caused text overflow, addition of characters to the end of
each line, etc.  In order to resolve this, we added our own &lt;a class="reference external" href="https://github.com/LibreTexts/ckeditor-binder-plugin/tree/staging/src/styles"&gt;styling&lt;/a&gt;
to the plugin. If one wishes to use the CKEditor plugin on their own pages,
they can remove the extra styling in the folder.&lt;/p&gt;
&lt;p&gt;Another difference was JavaScript conflict. When we were trying to support
Jupyter Widgets, we found that it depended on Require.js. However, adding
Require.js to Mindtouch would break all the JQuery plugins. In order to fix all
the JavaScript conflicts, we created registerPlugin.js to include all Mindtouch
specific JavaScript code.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="including-different-programming-languages"&gt;
&lt;h3&gt;Including different programming languages&lt;/h3&gt;
&lt;p&gt;During development, we used &lt;a class="reference external" href="https://github.com/binder-examples"&gt;environments developed by the Jupyter project&lt;/a&gt;. Using their Binder environments helped
us test and include different languages in our editor. Eventually we will
utilize, we would utilize the same &lt;a class="reference external" href="https://github.com/libretexts/default-env"&gt;default environment&lt;/a&gt; in our JupyterHub for our
editor. This default environment contains many packages that are commonly used
and requested by students and faculty.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="github-actions"&gt;
&lt;h3&gt;Github Actions&lt;/h3&gt;
&lt;p&gt;We made use of Github Actions to automate two important tasks. After each push
on Github, it will trigger our custom linter to ensure code quality and
consistency. Additionally, if we push any code to the master branch, it will
trigger an automatic deploy to production.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="ckeditor-capabilities"&gt;
&lt;h2&gt;CKEditor Capabilities&lt;/h2&gt;
&lt;p&gt;Currently authors publishing on the LibreTexts platform have the option to
insert executable code blocks using &lt;tt class="docutils literal"&gt;Octave&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;SageMath&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;Julia&lt;/tt&gt;, &lt;tt class="docutils literal"&gt;R&lt;/tt&gt;,
&lt;tt class="docutils literal"&gt;Python&lt;/tt&gt;, and &lt;tt class="docutils literal"&gt;C++&lt;/tt&gt;. There is a possibility that other languages may be
added in the future. Authors can choose to either copy and paste their code
into the text editor, or directly code in the text editor as they would any
other one. To ensure that it is easy for the author as well as the reader of
the textbook to view the contents within the code block, as described in the
aforementioned section, syntax highlighting is made available via
&lt;tt class="docutils literal"&gt;CodeMirror&lt;/tt&gt; for all the languages except &lt;tt class="docutils literal"&gt;SageMath&lt;/tt&gt; which is not supported
by &lt;tt class="docutils literal"&gt;CodeMirror&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;It is important to note that we suggest authors &lt;tt class="docutils literal"&gt;run&lt;/tt&gt; the sample &lt;tt class="docutils literal"&gt;Hello
World&lt;/tt&gt; print statement first to get the kernel started, once that is
successful, code can be added in the dialog box. For &lt;tt class="docutils literal"&gt;C++&lt;/tt&gt;, if the code has
already been &lt;tt class="docutils literal"&gt;run&lt;/tt&gt;, but the author wants to make any changes, they will need
to &lt;tt class="docutils literal"&gt;restart&lt;/tt&gt; the kernel in order to avoid an &lt;tt class="docutils literal"&gt;Interpreter Error&lt;/tt&gt; as any
variables will be assigned more than once in &lt;tt class="docutils literal"&gt;Binder&lt;/tt&gt; which is not allowed in
&lt;tt class="docutils literal"&gt;C++&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Packages and libraries can be exported as they normally would; however, if an
author finds that a specific package or library that they would like to use is
not currently available they can make a request to have it added by either
sending an &lt;a class="reference external" href="mailto:jupyterteam&amp;#64;ucdavis.edu"&gt;email to the Jupyter Team&lt;/a&gt;, linked in
the dialog box, or &lt;a class="reference external" href="https://github.com/LibreTexts/ckeditor-binder-plugin/issues"&gt;open an issue&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;Once the author is ready to insert the code block into their textbook page,
they have the option to either 'Insert with code and output,' 'Insert with code
only,' or 'Insert with output only.' Selection of any of these choices depends
on how the author intends to communicate the information provided in the code
block. If the code block has already been inserted into the page, and the
author wants to make any changes, they can simply double click on that section
and the dialog box will pop back up.&lt;/p&gt;
&lt;div class="figure align-center"&gt;
&lt;img alt="GIF depicting an example page made using CKEditor" src="https://objects-us-east-1.dream.io/mechmotum/example-libretexts-jupyter-page.gif" style="width: 100%;" /&gt;
&lt;p class="caption"&gt;&lt;em&gt;Figure 1: Example of what and author can do with CKEditor, and what the output will look like&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="future"&gt;
&lt;h2&gt;Future&lt;/h2&gt;
&lt;p&gt;As mentioned before, a long term goal is to use &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;default-env&lt;/span&gt;&lt;/tt&gt; for the
packages, this is the same environment that is used for the LIbreTexts-UCD
JupyterHub, and by&lt;/p&gt;
&lt;p&gt;using this, authors will have a greater selection of packages and libraries to
choose from, and it will also be easier for us to maintain. We also want to
improve the execution time of the code blocks, as currently requesting a kernel
involves downloading an image from DockerHub and creating a Docker container.&lt;/p&gt;
&lt;/div&gt;
</content><category term="education"></category><category term="oer"></category><category term="education"></category><category term="jupyter"></category><category term="textbooks"></category><category term="engineering"></category><category term="libretexts"></category></entry><entry><title>Slidedeck From Our Recent SacPy Talk</title><link href="https://mechmotum.github.io/blog/sacpy-slideck-2019.html" rel="alternate"></link><published>2019-11-17T00:00:00-08:00</published><updated>2019-11-17T00:00:00-08:00</updated><author><name>Jason K. Moore</name></author><id>tag:mechmotum.github.io,2019-11-17:/blog/sacpy-slideck-2019.html</id><summary type="html">&lt;p class="first last"&gt;Our slides from our November SacPy talk.&lt;/p&gt;
</summary><content type="html">&lt;iframe
src="https://docs.google.com/presentation/d/e/2PACX-1vQpprGVUh86uBUcpdQO-BD9-HQc0zit0vhf2O3z8Izs4aeYKcb8FxSX8gc43CeVM0-x_5JhIj03vRM0/embed?start=false&amp;loop=false&amp;delayms=3000"
frameborder="0" width="960" height="569" allowfullscreen="true"
mozallowfullscreen="true" webkitallowfullscreen="true"&gt;&lt;/iframe&gt;&lt;div class="figure align-center"&gt;
&lt;img alt="Celine presenting at SacPy." src="https://objects-us-east-1.dream.io/mechmotum/celine-sacpy.jpg" style="width: 800px;" /&gt;
&lt;p class="caption"&gt;Celine presenting at SacPy.&lt;/p&gt;
&lt;/div&gt;
</content><category term="education"></category><category term="oer"></category><category term="education"></category><category term="jupyter"></category><category term="textbooks"></category><category term="engineering"></category><category term="python"></category></entry><entry><title>Creating a Kubernetes Bare-Metal Cluster for JupyterHub</title><link href="https://mechmotum.github.io/blog/jupyter-summer-2019.html" rel="alternate"></link><published>2019-11-01T00:00:00-07:00</published><updated>2019-11-01T00:00:00-07:00</updated><author><name>Xin Luigi Chen</name></author><id>tag:mechmotum.github.io,2019-11-01:/blog/jupyter-summer-2019.html</id><summary type="html">&lt;p class="first last"&gt;Blog post on setting up JupyterHub on a Kubernetes bare-metal cluster&lt;/p&gt;
</summary><content type="html">&lt;div class="section" id="background"&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;During the spring quarter and summer sessions, we focused on creating a
Kubernetes bare-metal cluster to deploy JupyterHub, BinderHub, and other
services.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="virtual-machine-cluster"&gt;
&lt;h2&gt;Virtual Machine Cluster&lt;/h2&gt;
&lt;p&gt;During spring quarter, Kevin and Celine worked on creating the bare metal
Kubernetes cluster. We first created a cluster of virtual machines (VMs) A
Linux test server served as the master node and host machine, while virtual
machines served as the child nodes. We used Vagrant to create these child nodes
and Ansible to provision them.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/LibreTexts/metalc/tree/master/dev-env"&gt;This folder in our main repository&lt;/a&gt; contains
instructions for setting up this development environment.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bare-metal-cluster"&gt;
&lt;h2&gt;Bare-Metal Cluster&lt;/h2&gt;
&lt;p&gt;Our original bare-metal cluster consists of one master node named chick0 and 11
children named chick1 through chick10 sequentially. It also contains a
management node called rooster, which acts as a DHCP server, a TFTP server for
NetBoot and a proxy between the Internet and the Kubernetes cluster. The
Kubernetes cluster is under a private network, so the only way to access the
Kubernetes cluster is by connecting through rooster.&lt;/p&gt;
&lt;p&gt;The following diagram describes our networking setup.&lt;/p&gt;
&lt;img alt="Kubernetes diagram of cluster" src="https://objects-us-east-1.dream.io/mechmotum/kubediagram.png" style="width: 600px;" /&gt;
&lt;p&gt;The private network is under the &lt;tt class="docutils literal"&gt;10.0.0.0/8&lt;/tt&gt;. Kubernetes uses this network
for its resources to communicate.  Rooster has a public IP address of
&lt;tt class="docutils literal"&gt;128.120.136.26&lt;/tt&gt;, which serves multiple services based on the domain name
entered by the user.&lt;/p&gt;
&lt;p&gt;All servers are connected to a smart switch. The ZFS server is also connected
to the switch and provides persistent storage of JupyterHub users' files.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://wiki.debian.org/PXEBootInstall#Preface"&gt;PXEBoot&lt;/a&gt; used a preseed
file and a DHCP server to install Ubuntu Server 18.04 on the servers more
efficiently. Each new server pulls the preseed and installation files via a
TFTP server set up on rooster.&lt;/p&gt;
&lt;p&gt;As done in the development environment, the nodes were provisioned using
&lt;a class="reference external" href="https://github.com/LibreTexts/metalc/tree/master/ansible/playbooks"&gt;Ansible scripts&lt;/a&gt;.
Unlike the development environment, the bare-metal cluster &lt;a class="reference external" href="https://medium.com/&amp;#64;jain.sm/flannel-vs-calico-a-battle-of-l2-vs-l3-based-networking-5a30cd0a3ebd"&gt;uses Calico instead
of Flannel&lt;/a&gt;
for pod networking. This was chosen because Calico doesn't require software
bridges or IP tunneling like Flannel does. When communicating from pod to pod,
Flannel requires the pod's IP to be &amp;quot;packaged&amp;quot; in another IP (IP tunneling) to
send to the other pod. Calico, on the other hand, uses BGP protocol and
conserves the original pod IP.&lt;/p&gt;
&lt;p&gt;When we first setup our bare-metal cluster, we used rooster for our storage
needs by running a NFS server on it. Once we started getting ready for
production, we decided that we needed a more robust and redundant option for
our storage needs. With that in mind, we met with Mike and Dean, folks from the
Bioinformatics Core at the Genome Center here at UC Davis, to discuss the best
storage setup for our needs. After a couple of meetings, we came to the
conclusion that a ZFS setup would make the most sense, this decision was
reached mostly because of factors such as hardware already available and the
experience on ZFS that Dean and Mike brought to the table.&lt;/p&gt;
&lt;p&gt;Thanks to a retired ZFS server called the 'Hyperserver', we didn't have to
spend time and money ordering parts for our design. The 'Hyperserver' was quite
fitting of its name as it was a behemoth compared to the other nodes that we
were used to working with. The 'Hyperserver' was a 4U rack with enough slots in
the front to fit 24 drives, and 12 additional slots in the back for more. With
the help of Mike and Dean, we updated the firmware on the motherboard, drives,
and IPMI controller before we installed 24 storage drives in the front, and 2
RAID1 OS drives, 2 zil caches and 2 hot spares in the back. We used 4 stripes
of 6 drives each with raidz2 for our data storage drives, the goal was to
maximize speed and redundancy.  With raidz2, each stripe could lose a maximum
of 2 disks at once and the ZFS would still work. We then hooked up the ZFS to
our smart-switch where the Kubernetes network lives.  We made use of the
10Gib/s intel network card with a short range transceiver and 10M copper wire.
After we finished setting the ZFS server up, we renamed it to 'hen' to go along
with our naming theme for our cluster. Anyone can check out our extensive
&lt;a class="reference external" href="https://github.com/LibreTexts/metalc/blob/master/docs/Bare-Metal/ZFS.md"&gt;documentation&lt;/a&gt;
for more information regarding how we setup our ZFS.&lt;/p&gt;
&lt;p&gt;For security, we mainly followed the guide, &lt;a class="reference external" href="https://github.com/imthenachoman/How-To-Secure-A-Linux-Server"&gt;How to Secure a Linux Server&lt;/a&gt; written by
GitHub user &lt;a class="reference external" href="https://github.com/imthenachoman"&gt;iamthenachoman&lt;/a&gt;. Using the
guide, we implemented SSHing into rooster using only an SSH public/private key
pair, cleaned up short keys and UFW rules, and added intrusion detection for
iptables, SSH, and rootkits. You could find more information on our security
implementation in &lt;a class="reference external" href="https://github.com/LibreTexts/metalc/blob/master/docs/Bare-Metal/baremetal.md#securing-the-cluster"&gt;this section&lt;/a&gt;
of our documentation.&lt;/p&gt;
&lt;p&gt;Later, we added more chicks and upgraded the RAM of almost all chicks. We
increased the number of worker nodes from 10 to 18, and upgraded the RAM on
most chicks from 16GB to 64GB. These efforts prepared the cluster for handling
new classes in the fall quarter.&lt;/p&gt;
&lt;p&gt;Our &lt;a class="reference external" href="https://github.com/LibreTexts/metalc/blob/master/docs/Bare-Metal/baremetal.md"&gt;documentation&lt;/a&gt;
details our setup further and describes the actions taken to build the cluster
from scratch.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="customizing-jupyterhub"&gt;
&lt;h2&gt;Customizing JupyterHub&lt;/h2&gt;
&lt;p&gt;We made many modifications to JupyterHub, including redesigning the website,
adding new default environments, and more.&lt;/p&gt;
&lt;p&gt;JupyterHub pages is customizable using the &lt;a class="reference external" href="https://jinja.palletsprojects.com/en/2.10.x/templates/"&gt;Jinja2 templating system&lt;/a&gt; .  There are two
ways to add custom HTML files to JupyterHub (as described in &lt;a class="reference external" href="https://discourse.jupyter.org/t/customizing-jupyterhub-on-kubernetes/1769"&gt;this Discourse
post&lt;/a&gt;):&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Through &lt;a class="reference external" href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/"&gt;InitContainers&lt;/a&gt; that
pull repositories of template files before the hub starts,&lt;/li&gt;
&lt;li&gt;Or through mounting &lt;a class="reference external" href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/"&gt;ConfigMaps&lt;/a&gt;
to the template file directory.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We chose the former option and have repositories for &lt;a class="reference external" href="https://github.com/LibreTexts/jupyterhub-templates"&gt;custom HTML files&lt;/a&gt; and &lt;a class="reference external" href="https://github.com/LibreTexts/jupyterhub-images"&gt;additional images&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is a screenshot of how the login page looks now.&lt;/p&gt;
&lt;img alt="Screenshot of the redesigned JupyterHub login page" src="https://objects-us-east-1.dream.io/mechmotum/jupyterhubscreenshot.png" style="width: 600px;" /&gt;
&lt;p&gt;Additionally, more spawner options are included. We modified the default
environment to include many packages requested by professors and students. The
Dockerfile for the default environment is maintained in &lt;a class="reference external" href="https://github.com/LibreTexts/default-env"&gt;this repository&lt;/a&gt;.  The environment includes
Python 2 and 3, Octave, R, Julia, and SageMath.  The default environment mainly
installs software and packages via apt and conda for security reasons.&lt;/p&gt;
&lt;img alt="Screenshot of the redesigned JupyterHub spawner page" src="https://objects-us-east-1.dream.io/mechmotum/jupyterhubspawner.png" style="width: 600px;" /&gt;
&lt;p&gt;The default environment includes Python 2 and 3, Octave, R, Julia, and
SageMath.  Note that SageMath requires Python 2, so changing the Python path
inside the SageMath configuration files is required. &lt;a class="reference external" href="https://bytesofcomputerwisdom.home.blog/2019/03/31/jupyter-notebook-running-the-wrong-python-version/"&gt;This article&lt;/a&gt;
contains more information on how this was accomplished. This fix is automated
in the Dockerfile.&lt;/p&gt;
&lt;p&gt;RStudio is also offered alongside JupyterLab, since deploying web applications
using packages such as &lt;tt class="docutils literal"&gt;shiny&lt;/tt&gt; and &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;shiny-dashboard&lt;/span&gt;&lt;/tt&gt; require RStudio and do
not run in Jupyter Notebooks.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="interesting-nuggets"&gt;
&lt;h2&gt;Interesting Nuggets&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Our Nginx server serves as a proxy to direct packets from public ips to ips
that metallb assigns to services on our cluster. When we setup HTTPS for
JupyterHub, Nginx started complaing as it would try to decrypt the traffic
meant for JupyterHub. We solved the problem by using the stream block, which
streams packet to the backend without trying to decrypt anything.&lt;/li&gt;
&lt;li&gt;A service on the cluster can be connected to a ingress controller(for example
Nginx) to make it accessible from outside the cluster. The ingress controller
is not to be confused with the Nginx proxy that we have running outside the
cluster, an ingress controller is a service running on Kubernetes that allows
host or URL based HTTP routing from outside the cluster to services on the
cluster.&lt;/li&gt;
&lt;li&gt;cert-manager is a very useful helm chart that can be deployed on Kubernetes
to automatically manage and issue TLS certificates from various issuing
sources. This alongside an ingress controller like Nginx can be a very useful
setup.&lt;/li&gt;
&lt;li&gt;Grafana and Prometheus is a good solution for setting up basic monitoring and
alerting on a Kubernetes cluster. They currently have a bug that erases all
the saved data when the Grafana pod is deleted for some reason. A workaround
is to save the json of the dashboards.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="future"&gt;
&lt;h2&gt;Future&lt;/h2&gt;
&lt;p&gt;In the future, we plan to create another cluster including, but not limited, to
the following:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Having multiple master nodes and using two HAproxy servers instead of a
single Nginx server to avoid single points of failure.&lt;/li&gt;
&lt;li&gt;Assigning GPU's to different users.&lt;/li&gt;
&lt;li&gt;Assigning different networks based on organization.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</content><category term="education"></category><category term="oer"></category><category term="education"></category><category term="jupyter"></category><category term="textbooks"></category><category term="engineering"></category><category term="libretexts"></category></entry><entry><title>Creating Linux Servers for JupyterHub</title><link href="https://mechmotum.github.io/blog/jupyter-winter-2019.html" rel="alternate"></link><published>2019-05-03T00:00:00-07:00</published><updated>2019-05-03T00:00:00-07:00</updated><author><name>Celine Liang</name></author><id>tag:mechmotum.github.io,2019-05-03:/blog/jupyter-winter-2019.html</id><summary type="html">&lt;p class="first last"&gt;Blog post on setting up JupyterHub for a future computing cluster&lt;/p&gt;
</summary><content type="html">&lt;div class="section" id="background"&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;As part of the &lt;a class="reference external" href="libretexts-grant.rst"&gt;$5M grant&lt;/a&gt; awarded to the LibreTexts
project last year, our team had two goals: to integrate Jupyter into the
LibreTexts website and to create a computing cluster running JupyterHub to
serve LibreTexts and UC Davis users. This quarter, we focused on researching
how to create the cluster through building test servers.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="virtual-machine-environment"&gt;
&lt;h2&gt;Virtual Machine Environment&lt;/h2&gt;
&lt;p&gt;The first step in our journey to building a cluster was to familiarize
ourselves with how to setup a single server. It was crucial for us to really
understand all the details on how to setup a single server, as we would need
the knowledge to setup each and every single node in the cluster. We decided to
use VirtualBox as our starting playground so we had an easily disposable
environments to learn from.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="raid1-and-lvm"&gt;
&lt;h2&gt;RAID1 and LVM&lt;/h2&gt;
&lt;p&gt;We started adding more features to the installations that we would eventually
use in our cluster configuration. We started by adding a software RAID1 to our
installations to familiarize ourselves with the process, and then we moved on
to adding LVM too.&lt;/p&gt;
&lt;p&gt;Redundant Array of Independent Disks, also known as RAID, provides multiple
ways of orchestrating and synchronizing multiple hard drives in a computer
network to establish reliable data storage within the network. We decided to
use RAID1, which consists of an exact copy of a set of data on two or more
disks. We chose RAID1 because it allows us to switch a drive while the server
is live, in case a drive fails.&lt;/p&gt;
&lt;p&gt;Logical Volume Manager, also known as LVM, is a device mapper target that
provides logical volume management for the Linux kernel. The benefits of using
LVM is the ability to use and manage &amp;quot;dynamic partitions&amp;quot;. When using LVM
&amp;quot;partitions&amp;quot;, known just as logical volumes, we can manage them very easily
through the command line if we wanted to either create additional partitions,
or resize/delete any existing partitions.&lt;/p&gt;
&lt;p&gt;While installing Ubuntu Live Server 18.04 with RAID1, we ran into an issue
where the server failed to start. According to the &lt;a class="reference external" href="https://wiki.ubuntu.com/BionicBeaver/ReleaseNotes#Server_installer"&gt;Ubuntu 18.04.02 Release
Notes&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The next generation Subiquity server installer, brings the comfortable live
session and speedy install of Ubuntu Desktop to server users at last.&lt;/p&gt;
&lt;p&gt;N.B., If you require multipath, full-disk encryption, or the ability to
re-using existing partitions, you will want to continue to use the alternate
installer which can be downloaded from
&lt;a class="reference external" href="http://cdimage.ubuntu.com/releases/18.04/release/"&gt;http://cdimage.ubuntu.com/releases/18.04/release/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As of 18.04.1, the Subiquity server installer now supports LVM, RAID, vlans,
and bonds.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After some researching, we learned however that &lt;a class="reference external" href="https://bugs.launchpad.net/subiquity/+bug/1785332"&gt;a bug&lt;/a&gt; from the Ubuntu Live
Server image caused the installer to fail to mount the boot partition,
preventing the installation of Ubuntu on RAID1. We instead used this &lt;a class="reference external" href="http://cdimage.ubuntu.com/releases/18.04.2/release/ubuntu-18.04.2-server-amd64.iso"&gt;alternate
installer (non-live server image file)&lt;/a&gt;
to successfully install Ubuntu Server 18.04 with RAID1 on the virtual machines.&lt;/p&gt;
&lt;p&gt;When installing Ubuntu Server with RAID1 and LVM on our virtual machines, we
did not allot enough space on our hard disks for the operating system and
JupyterHub combined. We determined that in total, the operating system and
JupyterHub required about 15 GB of storage. To be safe, we now recommend to
create two 20 GB virtual hard disks for setting up JupyterHub.&lt;/p&gt;
&lt;p&gt;Our individual setups varied between each test server. In one successful setup,
each hard disk contained two partitions. One partition contained 2.0 GB and was
mounted on &lt;tt class="docutils literal"&gt;/boot&lt;/tt&gt; as the boot partition. The other partition contained 19.5
GB, serving as primary storage.&lt;/p&gt;
&lt;p&gt;We plan to have a stack of Ubuntu 18, RAID1, and LVM as our standard setup for
each node in the cluster.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="jupyterhub-bare-metal"&gt;
&lt;h2&gt;JupyterHub Bare-Metal&lt;/h2&gt;
&lt;p&gt;Our next step was trying to setup a bare-metal verion of JupyterHub in our
virtual machines.  We followed the instructions provided in the repository,
&lt;a class="reference external" href="https://github.com/mechmotum/jupyterhub-deploy-teaching"&gt;jupyterhub-deploy-teaching&lt;/a&gt;, to install
JupyterHub on our virtual machines and connect to it through the browser. The
repository is a &amp;quot;light fork&amp;quot; from the JupyterHub's &lt;a class="reference external" href="https://github.com/jupyterhub/jupyterhub-deploy-teaching"&gt;original
jupyterhub-deploy-teaching&lt;/a&gt; repository,
intended for UC Davis usage.&lt;/p&gt;
&lt;p&gt;We ran into a few issues during the installation process.  The Ansible script
in the repository was missing some required installations.  The package
&lt;cite&gt;python3-distutils&lt;/cite&gt; is required by JupyterHub but was not installed. The
package was a part of Ubuntu 16.04, so the Ansible script did not need to
specify installing &lt;tt class="docutils literal"&gt;&lt;span class="pre"&gt;python3-disutils&lt;/span&gt;&lt;/tt&gt; previously. This was fixed in the
Ansible Playbook via &lt;a class="reference external" href="https://github.com/mechmotum/jupyterhub-deploy-teaching/commit/51b070a9ae3223d1919ec56323411ef455d642e5"&gt;this commit&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We also encountered Conda errors while installing JupyterHub. We suspect that
this is due to the submodules from the &lt;a class="reference external" href="https://github.com/UDST/ansible-conda/tree/f26ac9f82bb96035d9d96a1531d62456c959229d"&gt;ansible-conda&lt;/a&gt;
repository, which are fixed by running their updates in our automatic
configuration and deploying script, &lt;tt class="docutils literal"&gt;setup.sh&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;After succeeding in setting up JupyterHub on our virtual machines, we
incorporated the changes into the configuration files and completed
&lt;tt class="docutils literal"&gt;setup.sh&lt;/tt&gt; to automate the installation process, testing it to make sure that
it worked. The script &lt;tt class="docutils literal"&gt;setup.sh&lt;/tt&gt; automates the following configuration tasks:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Adds submodules from the &lt;a class="reference external" href="https://github.com/UDST/ansible-conda/tree/f26ac9f82bb96035d9d96a1531d62456c959229d"&gt;ansible-conda&lt;/a&gt;
repository.&lt;/li&gt;
&lt;li&gt;Adds the current user to as an admin and user.&lt;/li&gt;
&lt;li&gt;Generates a proxy_auth_token and inputs it into the configuration file.&lt;/li&gt;
&lt;li&gt;Generates a self-signed SSL certificate and cookie secret.&lt;/li&gt;
&lt;li&gt;Names the &lt;cite&gt;hosts&lt;/cite&gt; and &lt;cite&gt;jupyter_hosts&lt;/cite&gt; files properly from &lt;cite&gt;hosts.example&lt;/cite&gt;
and &lt;cite&gt;jupyter_hosts.example&lt;/cite&gt; respectively.&lt;/li&gt;
&lt;li&gt;Runs Ansible Playbook.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Users can now save time by running the script to configure and deploy
JupyterHub, rather than complete the above tasks manually. Using the script
should be less error-prone compared to the manual setup.&lt;/p&gt;
&lt;/div&gt;
</content><category term="education"></category><category term="oer"></category><category term="education"></category><category term="jupyter"></category><category term="textbooks"></category><category term="engineering"></category><category term="libretexts"></category></entry></feed>